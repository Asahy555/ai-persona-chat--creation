import { NextResponse } from 'next/server';
import { processWithNarrator } from '@/lib/narrator-service';
import { LLMConfig } from '@/lib/llm-service';

export async function POST(request: Request) {
  try {
    const { message, personalities, conversationHistory, apiConfig } = await request.json();

    if (!message || !personalities || !Array.isArray(personalities)) {
      return NextResponse.json(
        { error: '–¢—Ä–µ–±—É—é—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –ª–∏—á–Ω–æ—Å—Ç–∏' },
        { status: 400 }
      );
    }

    console.log(`üé≠ Processing message with ${personalities.length} character(s) via Narrator...`);

    // Use API config from request if provided
    const config: LLMConfig = apiConfig || {};

    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–∞–≤–Ω—É—é –º–æ–¥–µ–ª—å-—Ä–∞—Å—Å–∫–∞–∑—á–∏–∫–∞
    const narratorResponse = await processWithNarrator(
      message,
      personalities,
      conversationHistory || [],
      config
    );

    console.log(`‚úÖ Narrator response generated with ${narratorResponse.characterResponses.length} character(s)`);

    return NextResponse.json({
      success: true,
      narratorResponse,
    });
  } catch (error) {
    console.error('–û—à–∏–±–∫–∞ –≤ –º–∞—Ä—à—Ä—É—Ç–µ —á–∞—Ç–∞:', error);
    return NextResponse.json(
      { error: '–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç', details: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}